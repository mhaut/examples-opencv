{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f87db4ee",
   "metadata": {},
   "source": [
    "## Tracking de objetos\n",
    "\n",
    "El seguimiento de objetos en OpenCV se puede realizar utilizando varios algoritmos, pero uno de los más populares es el algoritmo de seguimiento de camino de color. Este algoritmo se basa en el seguimiento de un objeto de un color específico dentro de una imagen o un video.\n",
    "\n",
    "A continuación, describo los pasos básicos para el seguimiento de objetos con OpenCV:\n",
    "\n",
    "Captura de la imagen o video: En primer lugar, se debe capturar la imagen o video que se desea procesar. Esto se puede realizar utilizando la función cv2.VideoCapture().\n",
    "\n",
    "Conversión a espacio de color HSV: El siguiente paso es convertir la imagen a un espacio de color HSV (Tono-Saturación-Luminosidad) en lugar de RGB. Esto es útil para el seguimiento de objetos de color ya que el espacio HSV es más adecuado para representar colores.\n",
    "\n",
    "Definición del rango de color: El siguiente paso es definir un rango de colores para el objeto que se desea seguir. Para esto, se utiliza la función cv2.inRange().\n",
    "\n",
    "Seguimiento de objeto: A continuación, se utiliza la función cv2.bitwise_and() para aplicar la máscara sobre la imagen y seguir el objeto de color específico.\n",
    "\n",
    "Dibujo de la caja alrededor del objeto: Finalmente, se puede dibujar una caja alrededor del objeto seguido utilizando las funciones cv2.rectangle() o cv2.boundingRect().\n",
    "\n",
    "Estos son los pasos básicos para el seguimiento de objetos en OpenCV, pero existen muchos otros algoritmos y técnicas que se pueden utilizar para mejorar la precisión y eficiencia del seguimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82746e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Iniciamos la captura de video\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Definimos el rango de color a seguir (en este caso, azul)\n",
    "lower_blue = np.array([110, 50, 50])\n",
    "upper_blue = np.array([130, 255, 255])\n",
    "\n",
    "# Creamos una máscara para filtrar solo los píxeles azules\n",
    "while True:\n",
    "    # Capturamos el frame actual\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Convertimos el frame a HSV\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Aplicamos la máscara para filtrar solo los píxeles azules\n",
    "    mask = cv2.inRange(hsv, lower_blue, upper_blue)\n",
    "\n",
    "    # Encontramos los contornos en la máscara\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Dibujamos un rectángulo alrededor del objeto azul más grande\n",
    "    if len(contours) > 0:\n",
    "        c = max(contours, key=cv2.contourArea)\n",
    "        (x, y, w, h) = cv2.boundingRect(c)\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    # Mostramos el frame resultante\n",
    "    cv2.imshow(\"Tracking\", frame)\n",
    "\n",
    "    # Salimos del bucle si se pulsa la tecla 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Liberamos la captura de video y cerramos las ventanas\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86530a26",
   "metadata": {},
   "source": [
    "## Detección de partes del cuerpo\n",
    "\n",
    "La detección de partes del cuerpo utiliza técnicas de visión por computadora y aprendizaje automático para identificar y localizar partes específicas del cuerpo humano, como rostros, manos, pies, etc., en imágenes o vídeos.\n",
    "\n",
    "Hay varios enfoques para la detección de partes del cuerpo con OpenCV, pero uno de los más comunes es utilizar detectores de objetos basados en cascadas de Haar. Estos detectores utilizan una técnica de aprendizaje automático para aprender a reconocer patrones en imágenes, y luego utilizar esos patrones para detectar objetos similares en nuevas imágenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88803d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "#ruta al clasificador haar\n",
    "pathfile = r'/home/maui/anaconda3/envs/sistmult/lib/python3.10/site-packages/cv2/data/haarcascade_frontalface_default.xml'\n",
    "# Cargar el clasificador\n",
    "face_cascade = cv2.CascadeClassifier(pathfile)\n",
    "\n",
    "# Leer la imagen de entrada\n",
    "img = cv2.imread('gente.jpg')\n",
    "\n",
    "# Convertirlo a escala de grises\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Detectar caras\n",
    "faces = face_cascade.detectMultiScale(gray, scaleFactor=1.2, minNeighbors=5)\n",
    "\n",
    "# Dibujar rectángulos alrededor de las caras\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(img, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "\n",
    "# Muestra la salida\n",
    "cv2.imshow('img', img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d68f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "#rutas a los clasificadores haar\n",
    "pathfile1 = r'/home/maui/anaconda3/envs/sistmult/lib/python3.10/site-packages/cv2/data/haarcascade_frontalface_default.xml'\n",
    "pathfile2 = r'/home/maui/anaconda3/envs/sistmult/lib/python3.10/site-packages/cv2/data/haarcascade_eye.xml'\n",
    "\n",
    "# Cargar los clasificadores\n",
    "face_cascade = cv2.CascadeClassifier(pathfile1)\n",
    "eye_cascade  = cv2.CascadeClassifier(pathfile2)\n",
    "\n",
    "# Leer la imagen de entrada\n",
    "img = cv2.imread('gente.jpeg')\n",
    "\n",
    "# Convertirlo a escala de grises\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Detectar caras\n",
    "faces = face_cascade.detectMultiScale(gray, scaleFactor=1.2, minNeighbors=5)\n",
    "# Detectar ojos\n",
    "eyes = eye_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
    "\n",
    "# Dibujar rectángulos alrededor de las caras\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(img, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "# Dibujar un rectángulo alrededor de cada ojo detectado\n",
    "for (x, y, w, h) in eyes:\n",
    "    cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "\n",
    "# Muestra la salida\n",
    "cv2.imshow('img', img)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9a44cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "#rutas a los clasificadores haar\n",
    "pathfile1 = r'/home/maui/anaconda3/envs/sistmult/lib/python3.10/site-packages/cv2/data/haarcascade_frontalface_default.xml'\n",
    "pathfile2 = r'/home/maui/anaconda3/envs/sistmult/lib/python3.10/site-packages/cv2/data/haarcascade_eye.xml'\n",
    "pathfile3 = r'/home/maui/anaconda3/envs/sistmult/lib/python3.10/site-packages/cv2/data/haarcascade_smile.xml'\n",
    "\n",
    "# Cargar los clasificadores\n",
    "face_cascade   = cv2.CascadeClassifier(pathfile1)\n",
    "eye_cascade    = cv2.CascadeClassifier(pathfile2)\n",
    "mouth_cascade  = cv2.CascadeClassifier(pathfile3)\n",
    "\n",
    "\n",
    "# Leer la imagen de entrada\n",
    "img = cv2.imread('gente.jpeg')\n",
    "\n",
    "# Convertirlo a escala de grises\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Detectar caras\n",
    "faces = face_cascade.detectMultiScale(gray, scaleFactor=1.2, minNeighbors=8)\n",
    "# Detectar ojos\n",
    "eyes = eye_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
    "# Detectar bocas\n",
    "mouths = mouth_cascade.detectMultiScale(gray, scaleFactor=1.5, minNeighbors=15)\n",
    "\n",
    "\n",
    "# Dibujar rectángulos alrededor de las caras\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(img, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "# Dibujar un rectángulo alrededor de cada ojo detectado\n",
    "for (x, y, w, h) in eyes:\n",
    "    cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "# Dibujar un rectángulo alrededor de la oreja\n",
    "for (x, y, w, h) in mouths:\n",
    "    cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    \n",
    "# Muestra la salida\n",
    "cv2.imshow('img', img)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
